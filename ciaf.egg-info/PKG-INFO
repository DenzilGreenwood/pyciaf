Metadata-Version: 2.4
Name: ciaf
Version: 1.0.0
Summary: Cognitive Insight Audit Framework - A comprehensive framework for verifiable AI training and inference pipelines
Author-email: Denzil James Greenwood <founder@cognitiveinsight.ai>
Maintainer-email: Denzil James Greenwood <founder@cognitiveinsight.ai>
License: MIT LicenseMIT License 
        
        Copyright Â© 2025 Denzil James Greenwood Founder@CognitiveInsight.AI
        
        Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the â€œSoftwareâ€), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
        
        The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
        
        THE SOFTWARE IS PROVIDED â€œAS ISâ€, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
Project-URL: Homepage, https://github.com/DenzilGreenwood/pyciaf
Project-URL: Documentation, https://ciaf.readthedocs.io
Project-URL: Repository, https://github.com/DenzilGreenwood/pyciaf
Project-URL: Bug Tracker, https://github.com/DenzilGreenwood/pyciaf/issues
Project-URL: Changelog, https://github.com/DenzilGreenwood/pyciaf/blob/main/CHANGELOG.md
Keywords: ai,artificial intelligence,machine learning,cryptography,provenance,compliance,gdpr,ai-act,nist,hipaa,audit,transparency,explainable-ai,uncertainty-quantification
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Security :: Cryptography
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: cryptography>=3.4.8
Requires-Dist: numpy>=1.21.0
Requires-Dist: scikit-learn>=1.0.0
Provides-Extra: full
Requires-Dist: shap>=0.41.0; extra == "full"
Requires-Dist: lime>=0.2.0.1; extra == "full"
Requires-Dist: matplotlib>=3.5.0; extra == "full"
Requires-Dist: seaborn>=0.11.0; extra == "full"
Requires-Dist: pandas>=1.3.0; extra == "full"
Requires-Dist: plotly>=5.0.0; extra == "full"
Provides-Extra: dev
Requires-Dist: pytest>=6.0.0; extra == "dev"
Requires-Dist: pytest-cov>=2.12.0; extra == "dev"
Requires-Dist: black>=21.0.0; extra == "dev"
Requires-Dist: flake8>=3.9.0; extra == "dev"
Requires-Dist: mypy>=0.910; extra == "dev"
Requires-Dist: pre-commit>=2.15.0; extra == "dev"
Provides-Extra: docs
Requires-Dist: sphinx>=4.0.0; extra == "docs"
Requires-Dist: sphinx-rtd-theme>=1.0.0; extra == "docs"
Requires-Dist: myst-parser>=0.15.0; extra == "docs"
Dynamic: license-file

# CIAF â€“ Cognitive Insight Audit Framework# CIAF â€“ Cognitive Insight Audit Framework



**Version:** 1.0.0**Version:** 1.0.0



A Python framework for verifiable AI training and inference with cryptographic provenance, selective ("lazy") capsule materialization, and compliance-ready audit receipts.A Python framework for verifiable AI training and inference with cryptographic provenance, selective ("lazy") capsule materialization, and compliance-ready audit receipts.



[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

![Python 3.9+](https://img.shields.io/badge/Python-3.9%2B-blue.svg)![Python 3.9+](https://img.shields.io/badge/Python-3.9%2B-blue.svg)

![Code Style: Black](https://img.shields.io/badge/code%20style-Black-000000.svg)![Code Style: Black](https://img.shields.io/badge/code%20style-Black-000000.svg)

[![Security Policy](https://img.shields.io/badge/Security-Policy-informational.svg)](ciaf/SECURITY.md)[![Security Policy](https://img.shields.io/badge/Security-Policy-informational.svg)](ciaf/SECURITY.md)



------



## Overview## Overview



CIAF (Cognitive Insight Audit Framework) addresses AI transparency, auditability, and compliance in production. It provides cryptographically verifiable provenance tracking, **Lazy Capsule Materialization (LCM)**, and audit artifacts designed to map to major regulatory frameworks.CIAF (Cognitive Insight Audit Framework) addresses AI transparency, auditability, and compliance in production. It provides cryptographically verifiable provenance tracking, **Lazy Capsule Materialization (LCM)**, and audit artifacts designed to map to major regulatory frameworks.



### Key Features### Key Features



- **Cryptographic Provenance Tracking** â€” End-to-end verifiable data lineage with Merkle trees and hash chains  - **Cryptographic Provenance Tracking** â€” End-to-end verifiable data lineage with Merkle trees and hash chains  

- **Lazy Capsule Materialization (LCM)** â€” On-demand proof capsule materialization to minimize storage and exposure  - **Lazy Capsule Materialization (LCM)** â€” On-demand proof capsule materialization to minimize storage and exposure  

- **Compliance Mapping** â€” Artifacts designed to map to EU AI Act, NIST AI RMF, GDPR/HIPAA, SOX, ISO/IEC 27001 (see `docs/compliance/`)  - **Compliance Mapping** â€” Artifacts designed to map to EU AI Act, NIST AI RMF, GDPR/HIPAA, SOX, ISO/IEC 27001 (see `docs/compliance/`)  

- **Security-First Design** â€” AES-256-GCM (optional), secure anchor derivation, tamper-evident audit trails  - **Security-First Design** â€” AES-256-GCM (optional), secure anchor derivation, tamper-evident audit trails  

- **Risk Assessment Patterns** â€” Bias/fairness checks and uncertainty quantification scaffolding  - **Risk Assessment Patterns** â€” Bias/fairness checks and uncertainty quantification scaffolding  

- **Transparency & Explainability** â€” Hooks for decision transparency and receipt generation  - **Transparency & Explainability** â€” Hooks for decision transparency and receipt generation  

- **Healthcare Patterns** â€” PHI minimization and consent tracking patterns (final compliance depends on deployment)  - **Healthcare Patterns** â€” PHI minimization and consent tracking patterns (final compliance depends on deployment)  

- **Performance Monitoring** â€” Basic metrics for LCM operations- **Performance Monitoring** â€” Basic metrics for LCM operations



------



## Installation## Installation



### Option A: From source### Option A: From source

```bash```bash

git clone https://github.com/DenzilGreenwood/pyciaf.gitgit clone https://github.com/DenzilGreenwood/pyciaf.git

cd pyciafcd pyciaf

python -m venv .venvpython -m venv .venv

# Windows: .venv\Scripts\activate# Windows: .venv\Scripts\activate

source .venv/bin/activatesource .venv/bin/activate

pip install -U pip buildpip install -U pip build

pip install -e .pip install -e .

``````



### Option B: Directly from GitHub## Option B: Directly from GitHub

```bash```bash

pip install "git+https://github.com/DenzilGreenwood/pyciaf.git#egg=ciaf"pip install "git+https://github.com/DenzilGreenwood/pyciaf.git#egg=ciaf"

``````



### Option C: PyPI (when published)### Option C: PyPI (when published)

```bash```bash

pip install pyciafpip install pyciaf

```

```

---

---

## Quick Start

## Quick Start

```python

from ciaf import CIAFFramework, ModelMetadataManager```python

from ciaf import CIAFFramework, ModelMetadataManager

framework = CIAFFramework("MyAI_Project")

framework = CIAFFramework("MyAI_Project")

# Dataset anchor (cryptographic root for dataset operations)

anchor = framework.create_dataset_anchor(# Dataset anchor (cryptographic root for dataset operations)

    dataset_id="healthcare_data",anchor = framework.create_dataset_anchor(

    dataset_metadata={"source": "hospital_system", "type": "medical_records"},    dataset_id="healthcare_data",

    master_password="secure_password_123"    dataset_metadata={"source": "hospital_system", "type": "medical_records"},

)    master_password="secure_password_123"

)

# Create provenance capsules

data_items = [# Create provenance capsules

    {"content": "patient_record_1", "metadata": {"id": "p001", "consent": True}},data_items = [

    {"content": "patient_record_2", "metadata": {"id": "p002", "consent": True}},    {"content": "patient_record_1", "metadata": {"id": "p001", "consent": True}},

]    {"content": "patient_record_2", "metadata": {"id": "p002", "consent": True}},

capsules = framework.create_provenance_capsules("healthcare_data", data_items)]

capsules = framework.create_provenance_capsules("healthcare_data", data_items)

# Model anchor (immutable parameter/architecture fingerprints + dataset authorization)

model_anchor = framework.create_model_anchor(# Model anchor (immutable parameter/architecture fingerprints + dataset authorization)

    model_name="diagnostic_model",model_anchor = framework.create_model_anchor(

    model_parameters={"epochs": 100, "lr": 0.001},    model_name="diagnostic_model",

    model_architecture={"type": "bert_classifier", "hidden": 768},    model_parameters={"epochs": 100, "lr": 0.001},

    authorized_datasets=["healthcare_data"],    model_architecture={"type": "bert_classifier", "hidden": 768},

    master_password="secure_model_password"    authorized_datasets=["healthcare_data"],

)    master_password="secure_model_password"

)

# Verifiable training snapshot

snapshot = framework.train_model(# Verifiable training snapshot

    model_name="diagnostic_model",snapshot = framework.train_model(

    capsules=capsules,    model_name="diagnostic_model",

    maa=model_anchor,    capsules=capsules,

    training_params={"epochs": 100, "lr": 0.001},    maa=model_anchor,

    model_version="v1.0"    training_params={"epochs": 100, "lr": 0.001},

)    model_version="v1.0"

)

# Integrity check

assert framework.validate_training_integrity(snapshot)# Integrity check

print("Training integrity verified.")assert framework.validate_training_integrity(snapshot)

```print("Training integrity verified.")

```

---

---

## Architecture

## Architecture

```scss

CIAF Framework```scss

â”œâ”€ Core ComponentsCIAF Framework

â”‚  â”œâ”€ Cryptographic Utilities (AES-256-GCM, SHA-256, HMAC)â”œâ”€ Core Components

â”‚  â”œâ”€ Anchor Management (hierarchical anchor derivation)â”‚  â”œâ”€ Cryptographic Utilities (AES-256-GCM, SHA-256, HMAC)

â”‚  â””â”€ Merkle Tree Implementationâ”‚  â”œâ”€ Anchor Management (hierarchical anchor derivation)

â”œâ”€ Anchoring Systemâ”‚  â””â”€ Merkle Tree Implementation

â”‚  â”œâ”€ Dataset Anchors (Master â†’ Dataset â†’ Capsule)â”œâ”€ Anchoring System

â”‚  â””â”€ Lazy Managers (selective materialization)â”‚  â”œâ”€ Dataset Anchors (Master â†’ Dataset â†’ Capsule)

â”œâ”€ Provenance Trackingâ”‚  â””â”€ Lazy Managers (selective materialization)

â”‚  â”œâ”€ Provenance Capsules (content + metadata)â”œâ”€ Provenance Tracking

â”‚  â””â”€ Training Snapshots (verifiable model states)â”‚  â”œâ”€ Provenance Capsules (content + metadata)

â”œâ”€ Compliance Engineâ”‚  â””â”€ Training Snapshots (verifiable model states)

â”‚  â”œâ”€ Regulatory Mapping (EU AI Act, NIST, GDPR/HIPAA, etc.)â”œâ”€ Compliance Engine

â”‚  â”œâ”€ Validators (automated checks, where implemented)â”‚  â”œâ”€ Regulatory Mapping (EU AI Act, NIST, GDPR/HIPAA, etc.)

â”‚  â””â”€ Audit Trails (append-only/WORM)â”‚  â”œâ”€ Validators (automated checks, where implemented)

â”œâ”€ Risk Assessmentâ”‚  â””â”€ Audit Trails (append-only/WORM)

â”‚  â”œâ”€ Bias & Fairness patternsâ”œâ”€ Risk Assessment

â”‚  â”œâ”€ Uncertainty quantification scaffoldingâ”‚  â”œâ”€ Bias & Fairness patterns

â”‚  â””â”€ Security assessment hooksâ”‚  â”œâ”€ Uncertainty quantification scaffolding

â”œâ”€ Metadata Managementâ”‚  â””â”€ Security assessment hooks

â”‚  â”œâ”€ Storage backends (JSON, SQLite, Pickle)â”œâ”€ Metadata Management

â”‚  â”œâ”€ Configuration templatesâ”‚  â”œâ”€ Storage backends (JSON, SQLite, Pickle)

â”‚  â””â”€ Integration utilitiesâ”‚  â”œâ”€ Configuration templates

â””â”€ Utilitiesâ”‚  â””â”€ Integration utilities

   â”œâ”€ CLI Toolsâ””â”€ Utilities

   â”œâ”€ Model Wrappers   â”œâ”€ CLI Tools

   â””â”€ ML Framework Simulators   â”œâ”€ Model Wrappers

```   â””â”€ ML Framework Simulators

```

---

---

## Compliance Support

## Compliance Support

**Compliance Mapping:** CIAF's audit artifacts are designed to map to control intents across EU AI Act, NIST AI RMF, GDPR/HIPAA, SOX, ISO/IEC 27001. Coverage varies by control and typically requires organizational process overlays. See `docs/compliance/` for current status and gaps. **This is not legal advice.**

**Compliance Mapping:** CIAF's audit artifacts are designed to map to control intents across EU AI Act, NIST AI RMF, GDPR/HIPAA, SOX, ISO/IEC 27001. Coverage varies by control and typically requires organizational process overlays. See `docs/compliance/` for current status and gaps. **This is not legal advice.**

---

---

## Advanced Features

## Advanced Features

### Lazy Capsule Materialization (LCM)

### Lazy Capsule Materialization (LCM)

Materialize only what you need, when you need itâ€”while preserving cryptographic verifiability.

Materialize only what you need, when you need itâ€”while preserving cryptographic verifiability.

```python

# Create dataset anchor with a lazy manager```python

anchor = framework.create_dataset_anchor(# Create dataset anchor with a lazy manager

    dataset_id="large_dataset",anchor = framework.create_dataset_anchor(

    dataset_metadata={"size": "1TB", "type": "image_data"},    dataset_id="large_dataset",

    master_password="secure_anchor_password"    dataset_metadata={"size": "1TB", "type": "image_data"},

)    master_password="secure_anchor_password"

)

# Access the dataset's lazy manager

lazy_manager = framework.lazy_managers["large_dataset"]# Access the dataset's lazy manager

lazy_manager = framework.lazy_managers["large_dataset"]

# Materialize a capsule on-demand

capsule = lazy_manager.materialize_capsule("item_001")# Materialize a capsule on-demand

```capsule = lazy_manager.materialize_capsule("item_001")

```

### Enhanced Model Anchor System

### Enhanced Model Anchor System

Immutable parameter/architecture fingerprints and dataset authorization.

Immutable parameter/architecture fingerprints and dataset authorization.

```python

model_anchor = framework.create_model_anchor(```python

    model_name="sentiment_classifier",model_anchor = framework.create_model_anchor(

    model_parameters={"learning_rate": 2e-5, "batch_size": 16, "num_epochs": 3, "model_type": "bert_classifier"},    model_name="sentiment_classifier",

    model_architecture={"base_model": "bert-base-uncased", "num_labels": 3, "hidden_size": 768},    model_parameters={"learning_rate": 2e-5, "batch_size": 16, "num_epochs": 3, "model_type": "bert_classifier"},

    authorized_datasets=["training_data_v1", "validation_data_v1"],    model_architecture={"base_model": "bert-base-uncased", "num_labels": 3, "hidden_size": 768},

    master_password="secure_model_password"    authorized_datasets=["training_data_v1", "validation_data_v1"],

)    master_password="secure_model_password"

)

print("Model fingerprint:", model_anchor["parameters_fingerprint"])

print("Architecture fingerprint:", model_anchor["architecture_fingerprint"])print("Model fingerprint:", model_anchor["parameters_fingerprint"])

```print("Architecture fingerprint:", model_anchor["architecture_fingerprint"])

```

### Complete Audit Flow Integration

### Complete Audit Flow Integration

```python

# 1) Train with complete audit```python

training_snapshot = framework.train_model_with_audit(# 1) Train with complete audit

    model_name="sentiment_classifier",training_snapshot = framework.train_model_with_audit(

    capsules=training_capsules,    model_name="sentiment_classifier",

    training_params=training_params,    capsules=training_capsules,

    model_version="1.0.0",    training_params=training_params,

    user_id="data_scientist_alice"    model_version="1.0.0",

)    user_id="data_scientist_alice"

)

# 2) Perform inference with audit chain

receipt = framework.perform_inference_with_audit(# 2) Perform inference with audit chain

    model_name="sentiment_classifier",receipt = framework.perform_inference_with_audit(

    query="This product is amazing!",    model_name="sentiment_classifier",

    ai_output="positive (confidence: 0.95)",    query="This product is amazing!",

    training_snapshot=training_snapshot,    ai_output="positive (confidence: 0.95)",

    user_id="api_user"    training_snapshot=training_snapshot,

)    user_id="api_user"

)

# 3) Retrieve complete audit trail

audit_trail = framework.get_complete_audit_trail("sentiment_classifier")# 3) Retrieve complete audit trail

print("Datasets:", audit_trail["verification"]["total_datasets"])audit_trail = framework.get_complete_audit_trail("sentiment_classifier")

print("Audit records:", audit_trail["verification"]["total_audit_records"])print("Datasets:", audit_trail["verification"]["total_datasets"])

print("Inference receipts:", audit_trail["inference_chain"]["total_receipts"])print("Audit records:", audit_trail["verification"]["total_audit_records"])

```print("Inference receipts:", audit_trail["inference_chain"]["total_receipts"])

```

---

---

## CLI Tools

## CLI Tools

```bash

# Setup metadata storage```bash

python -m ciaf.cli setup my_project --backend sqlite --template production# Setup metadata storage

python -m ciaf.cli setup my_project --backend sqlite --template production

# Generate compliance report

python -m ciaf.cli compliance eu_ai_act my_model_id --format html --output compliance_report.html# Generate compliance report

```python -m ciaf.cli compliance eu_ai_act my_model_id --format html --output compliance_report.html

```

---

---

## Integration Examples

## Integration Examples

### Scikit-learn

### Scikit-learn

```python

from ciaf import CIAFModelWrapper```python

from sklearn.ensemble import RandomForestClassifierfrom ciaf import CIAFModelWrapper

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()

wrapped = CIAFModelWrapper(model, "fraud_detection_v1")model = RandomForestClassifier()

wrapped = CIAFModelWrapper(model, "fraud_detection_v1")

wrapped.fit(X_train, y_train)

preds = wrapped.predict(X_test)wrapped.fit(X_train, y_train)

```preds = wrapped.predict(X_test)

```

### TensorFlow / PyTorch (simulated)

### TensorFlow / PyTorch (simulated)

```python

from ciaf.simulation import MLFrameworkSimulator```python

from ciaf.simulation import MLFrameworkSimulator

sim = MLFrameworkSimulator("neural_network")

training_snapshot = sim.train_model(sim = MLFrameworkSimulator("neural_network")

    training_data_capsules=capsules,training_snapshot = sim.train_model(

    maa=model_anchor,    training_data_capsules=capsules,

    training_params={"epochs": 50, "batch_size": 32},    maa=model_anchor,

    model_version="v2.0"    training_params={"epochs": 50, "batch_size": 32},

)    model_version="v2.0"

```)

```

---

---

## Performance & Metrics

## Performance & Metrics

```python

metrics = framework.get_performance_metrics("my_dataset")```python

print("Materialization rate:", f"{metrics['materialization_rate']:.2%}")metrics = framework.get_performance_metrics("my_dataset")

print("Total items:", metrics["total_items"])print("Materialization rate:", f"{metrics['materialization_rate']:.2%}")

print("Materialized capsules:", metrics["materialized_capsules"])print("Total items:", metrics["total_items"])

```print("Materialized capsules:", metrics["materialized_capsules"])

```

---

---

## Security

## Security

> **See our [Security Policy](ciaf/SECURITY.md) for reporting vulnerabilities, supported versions, and secure deployment guidance.**

> **See our [Security Policy](ciaf/SECURITY.md) for reporting vulnerabilities, supported versions, and secure deployment guidance.**

### Cryptographic Security

### Cryptographic Security

- **AES-256-GCM**: optional authenticated encryption (with AAD)

- **SHA-256**: hashing for integrity verification- **AES-256-GCM**: optional authenticated encryption (with AAD)

- **HMAC-SHA-256**: anchor derivation and message authentication- **SHA-256**: hashing for integrity verification

- **Merkle Trees**: canonical binary concatenation for tamper-evident sets- **HMAC-SHA-256**: anchor derivation and message authentication

- **Merkle Trees**: canonical binary concatenation for tamper-evident sets

### Anchor Management

### Anchor Management

- Hierarchical anchor derivation (Master â†’ Dataset â†’ Capsule)

- Cryptographically secure randomness- Hierarchical anchor derivation (Master â†’ Dataset â†’ Capsule)

- High-entropy binary anchors- Cryptographically secure randomness

- Canonicalized operations for derivations & Merkle policies- High-entropy binary anchors

- Backwards compatibility for legacy key-based terminology- Canonicalized operations for derivations & Merkle policies

- Backwards compatibility for legacy key-based terminology

### Access Controls (patterns)

### Access Controls (patterns)

- Role-based access patterns

- Audit logging hooks- Role-based access patterns

- Session management scaffolding- Audit logging hooks

- Session management scaffolding

---

---

## Healthcare & HIPAA Patterns

## Healthcare & HIPAA Patterns

```python

from ciaf import ModelMetadataManager```python

from ciaf.compliance import ComplianceFrameworkfrom ciaf import ModelMetadataManager

from ciaf.compliance import ComplianceFramework

manager = ModelMetadataManager("healthcare_ai", "1.0.0")

manager.enable_phi_protection()manager = ModelMetadataManager("healthcare_ai", "1.0.0")

manager.set_compliance_frameworks([ComplianceFramework.HIPAA])manager.enable_phi_protection()

manager.set_compliance_frameworks([ComplianceFramework.HIPAA])

manager.capture_metadata({

    "patient_id": "XXXXX",     # handled with PHI patternsmanager.capture_metadata({

    "diagnosis": "diabetes",    "patient_id": "XXXXX",     # handled with PHI patterns

    "consent_status": "active"    "diagnosis": "diabetes",

})    "consent_status": "active"

```})

```

> **Note:** CIAF provides patterns for PHI minimization and consent tracking. Final compliance depends on your deployment architecture, governance, and policies.

> **Note:** CIAF provides patterns for PHI minimization and consent tracking. Final compliance depends on your deployment architecture, governance, and policies.

---

---

## Contributing

## Contributing

We welcome contributions!

We welcome contributions!

1. **Code Style** â€” Black

2. **Testing** â€” Add tests; ensure all pass1. **Code Style** â€” Black

3. **Docs** â€” Update documentation for any API changes2. **Testing** â€” Add tests; ensure all pass

4. **Security** â€” Follow secure coding practices; report issues via `SECURITY.md`3. **Docs** â€” Update documentation for any API changes

4. **Security** â€” Follow secure coding practices; report issues via `SECURITY.md`

### Development Setup

### Development Setup

```bash

git clone https://github.com/DenzilGreenwood/pyciaf.git```bash

cd pyciafgit clone https://github.com/DenzilGreenwood/pyciaf.git

pip install -e .cd pyciaf

```pip install -e .

```

---

---

## Support & Community

## Support & Community

- **Documentation**: [https://ciaf.readthedocs.io](https://ciaf.readthedocs.io)

- **Issues**: [https://github.com/DenzilGreenwood/pyciaf/issues](https://github.com/DenzilGreenwood/pyciaf/issues)- **Documentation**: [https://ciaf.readthedocs.io](https://ciaf.readthedocs.io)

- **Discussions**: [https://github.com/DenzilGreenwood/pyciaf/discussions](https://github.com/DenzilGreenwood/pyciaf/discussions)- **Issues**: [https://github.com/DenzilGreenwood/pyciaf/issues](https://github.com/DenzilGreenwood/pyciaf/issues)

- **Security**: [Security Policy](ciaf/SECURITY.md)- **Discussions**: [https://github.com/DenzilGreenwood/pyciaf/discussions](https://github.com/DenzilGreenwood/pyciaf/discussions)

- **Security**: [Security Policy](ciaf/SECURITY.md)

---

---

## License

## License

This project is licensed under the MIT License â€” see [LICENSE](LICENSE) for details.

This project is licensed under the MIT License â€” see [LICENSE](LICENSE) for details.

---

---

## Acknowledgments

## Acknowledgments

- **cryptography** library and broader Python security ecosystem

- **Regulatory frameworks**: EU AI Act, NIST AI RMF, GDPR/HIPAA, ISO/IEC 27001, SOX (for mapping inspiration)- **cryptography** library and broader Python security ecosystem

- **Regulatory frameworks**: EU AI Act, NIST AI RMF, GDPR/HIPAA, ISO/IEC 27001, SOX (for mapping inspiration)

> **Personal note:** This project is a work in progress and reflects a commitment to secure, verifiable, and compliant AI systems. Feedback and contributions are highly appreciated!

> > **Personal note:** This project is a work in progress and reflects a commitment to secure, verifiable, and compliant AI systems. Feedback and contributions are highly appreciated!

> *â€” Denzil James Greenwood*> 
> *â€” Denzil James Greenwood*    master_password="secure_password_123"

CIAF Framework

â”œâ”€â”€ Core Components)

â”‚   â”œâ”€â”€ Cryptographic Utilities (AES-256-GCM, SHA256, HMAC)

â”‚   â”œâ”€â”€ Anchor Management (Hierarchical anchor derivation)```python

â”‚   â””â”€â”€ Merkle Tree Implementation

â”œâ”€â”€ Anchoring Systemfrom ciaf import CIAFFramework, ModelMetadataManager# Create provenance capsules for your data

â”‚   â”œâ”€â”€ Dataset Anchors (Master anchor â†’ Dataset anchor â†’ Capsule anchors)

â”‚   â””â”€â”€ Lazy Managers (Efficient capsule materialization)data_items = [

â”œâ”€â”€ Provenance Tracking

â”‚   â”œâ”€â”€ Provenance Capsules (Encrypted data with metadata)framework = CIAFFramework("MyAI_Project")    {"content": "patient_record_1", "metadata": {"id": "p001", "consent": True}},

â”‚   â””â”€â”€ Training Snapshots (Verifiable model states)

â”œâ”€â”€ Compliance Engine    {"content": "patient_record_2", "metadata": {"id": "p002", "consent": True}}

â”‚   â”œâ”€â”€ Regulatory Mapping (EU AI Act, NIST, GDPR, HIPAA, etc.)

â”‚   â”œâ”€â”€ Validators (Automated compliance checking)# Dataset anchor (cryptographic root for dataset operations)]

â”‚   â””â”€â”€ Audit Trails (Immutable event logging)

â”œâ”€â”€ Risk Assessmentanchor = framework.create_dataset_anchor(

â”‚   â”œâ”€â”€ Bias Detection & Fairness Validation

â”‚   â”œâ”€â”€ Uncertainty Quantification    dataset_id="healthcare_data",capsules = framework.create_provenance_capsules("healthcare_data", data_items)

â”‚   â””â”€â”€ Security Assessment

â”œâ”€â”€ Metadata Management    dataset_metadata={"source": "hospital_system", "type": "medical_records"},

â”‚   â”œâ”€â”€ Storage Backends (JSON, SQLite, Pickle)

â”‚   â”œâ”€â”€ Configuration Templates    master_password="secure_password_123"# Create Model Aggregation Anchor for training authorization

â”‚   â””â”€â”€ Integration Utilities

â””â”€â”€ Utilities)maa = framework.create_model_aggregation_anchor(

    â”œâ”€â”€ CLI Tools

    â”œâ”€â”€ Model Wrappers    model_name="diagnostic_model", 

    â””â”€â”€ ML Framework Simulators

```# Create provenance capsules    authorized_datasets=["healthcare_data"]



## Compliance Supportdata_items = [)



**Compliance Mapping:** CIAF maps audit artifacts to controls in EU AI Act, NIST AI RMF, GDPR/HIPAA, SOX, ISO/IEC 27001. Coverage varies by control; see `docs/compliance/` for current status and gaps.    {"content": "patient_record_1", "metadata": {"id": "p001", "consent": True}},



### EU AI Act    {"content": "patient_record_2", "metadata": {"id": "p002", "consent": True}},# Train your model with verifiable provenance

- Risk Management System patterns

- Quality Management System templates]snapshot = framework.train_model(

- Data Governance & Bias Monitoring tools

- Technical Documentation generationcapsules = framework.create_provenance_capsules("healthcare_data", data_items)    model_name="diagnostic_model",

- Record Keeping & Audit Trails

    capsules=capsules,

### NIST AI Risk Management Framework

- AI Risk Management Strategy templates# Model anchor (immutable parameter/architecture fingerprints + dataset authorization)    maa=maa,

- AI System Inventory & Mapping

- Impact Assessment toolsmodel_anchor = framework.create_model_anchor(    training_params={"epochs": 100, "lr": 0.001},

- Continuous Monitoring patterns

    model_name="diagnostic_model",    model_version="v1.0"

### Data Protection (GDPR, HIPAA, CCPA)

- Data Subject Rights Management patterns    model_parameters={"epochs": 100, "lr": 0.001},)

- Consent Tracking & Validation

- Data Minimization & Purpose Limitation    model_architecture={"type": "bert_classifier", "hidden": 768},

- Breach Detection & Notification

    authorized_datasets=["healthcare_data"],# Validate training integrity

### Financial & Security (SOX, PCI DSS, ISO 27001)

- Internal Controls Over Financial Reporting    master_password="secure_model_password"is_valid = framework.validate_training_integrity(snapshot)

- Documentation & Retention

- Information Security Management)print(f"Training integrity verified: {is_valid}")

- Access Controls & Monitoring

```

## Advanced Features

# Verifiable training snapshot

### Lazy Capsule Materialization (LCM)

snapshot = framework.train_model(## ğŸ—ï¸ Architecture

CIAF's LCM system allows efficient handling of large datasets:

    model_name="diagnostic_model",

```python

# Create dataset anchor with lazy manager    capsules=capsules,CIAF follows a modular architecture with clear separation of concerns:

# The anchor provides the cryptographic foundation for secure lazy evaluation

anchor = framework.create_dataset_anchor(    maa=model_anchor,

    dataset_id="large_dataset",

    dataset_metadata={"size": "1TB", "type": "image_data"},    training_params={"epochs": 100, "lr": 0.001},```

    master_password="secure_anchor_password"

)    model_version="v1.0"ğŸ“¦ CIAF Framework



# Capsules are created on-demand, not stored in memory)â”œâ”€â”€ ğŸ”‘ Core Components

# Each capsule is derived from the dataset anchor on materialization

lazy_manager = framework.lazy_managers["large_dataset"]â”‚   â”œâ”€â”€ Cryptographic Utilities (AES-256-GCM, SHA256, HMAC)



# Materialize only when needed - anchor provides cryptographic verification# Integrity checkâ”‚   â”œâ”€â”€ Anchor Management (Hierarchical anchor derivation)

capsule = lazy_manager.materialize_capsule("item_001")

```assert framework.validate_training_integrity(snapshot)â”‚   â””â”€â”€ Merkle Tree Implementation



### Enhanced Model Anchor Systemprint("Training integrity verified.")â”œâ”€â”€ âš“ Anchoring System



**NEW**: Comprehensive model tracking with immutable parameter fingerprinting:```â”‚   â”œâ”€â”€ Dataset Anchors (Master anchor â†’ Dataset anchor â†’ Capsule anchors)



```pythonâ”‚   â””â”€â”€ Lazy Managers (Efficient capsule materialization)

from ciaf import CIAFFramework

## Architectureâ”œâ”€â”€ ğŸ“¦ Provenance Tracking

framework = CIAFFramework("MyAI_Project")

â”‚   â”œâ”€â”€ Provenance Capsules (Encrypted data with metadata)

# Create model anchor with parameter hashing (ENHANCED FEATURE)

model_anchor = framework.create_model_anchor(CIAF follows a modular architecture with clear separation of concerns:â”‚   â””â”€â”€ Training Snapshots (Verifiable model states)

    model_name="diagnostic_model",

    model_parameters={â”œâ”€â”€ ğŸ›¡ï¸ Compliance Engine

        "learning_rate": 2e-5,

        "batch_size": 16,```â”‚   â”œâ”€â”€ Regulatory Mapping (EU AI Act, NIST, GDPR, HIPAA, etc.)

        "num_epochs": 3,

        "model_type": "bert_classifier"CIAF Frameworkâ”‚   â”œâ”€â”€ Validators (Automated compliance checking)

    },

    model_architecture={â”œâ”€â”€ Core Componentsâ”‚   â””â”€â”€ Audit Trails (Immutable event logging)

        "base_model": "bert-base-uncased",

        "num_labels": 3,â”‚   â”œâ”€â”€ Cryptographic Utilities (AES-256-GCM, SHA256, HMAC)â”œâ”€â”€ ğŸ¯ Risk Assessment

        "hidden_size": 768

    },â”‚   â”œâ”€â”€ Anchor Management (Hierarchical anchor derivation)â”‚   â”œâ”€â”€ Bias Detection & Fairness Validation

    authorized_datasets=["training_data_v1", "validation_data_v1"],

    master_password="secure_model_password"â”‚   â””â”€â”€ Merkle Tree Implementationâ”‚   â”œâ”€â”€ Uncertainty Quantification

)

â”œâ”€â”€ Anchoring Systemâ”‚   â””â”€â”€ Security Assessment

print(f"Model fingerprint: {model_anchor['parameters_fingerprint']}")

print(f"Architecture fingerprint: {model_anchor['architecture_fingerprint']}")â”‚   â”œâ”€â”€ Dataset Anchors (Master anchor â†’ Dataset anchor â†’ Capsule anchors)â”œâ”€â”€ ğŸ“Š Metadata Management

```

â”‚   â””â”€â”€ Lazy Managers (Efficient capsule materialization)â”‚   â”œâ”€â”€ Storage Backends (JSON, SQLite, Pickle)

### Complete Audit Flow Integration

â”œâ”€â”€ Provenance Trackingâ”‚   â”œâ”€â”€ Configuration Templates

**NEW**: End-to-end audit trail from dataset to inference:

â”‚   â”œâ”€â”€ Provenance Capsules (Encrypted data with metadata)â”‚   â””â”€â”€ Integration Utilities

```python

# Step 1: Train with complete auditâ”‚   â””â”€â”€ Training Snapshots (Verifiable model states)â””â”€â”€ ğŸ”§ Utilities

training_snapshot = framework.train_model_with_audit(

    model_name="diagnostic_model",â”œâ”€â”€ Compliance Engine    â”œâ”€â”€ CLI Tools

    capsules=training_capsules,

    training_params=training_params,â”‚   â”œâ”€â”€ Regulatory Mapping (EU AI Act, NIST, GDPR, HIPAA, etc.)    â”œâ”€â”€ Model Wrappers

    model_version="1.0.0",

    user_id="data_scientist_alice"â”‚   â”œâ”€â”€ Validators (Automated compliance checking)    â””â”€â”€ ML Framework Simulators

)

â”‚   â””â”€â”€ Audit Trails (Immutable event logging)```

# Step 2: Perform inference with audit chain

receipt = framework.perform_inference_with_audit(â”œâ”€â”€ Risk Assessment

    model_name="diagnostic_model",

    query="This product is amazing!",â”‚   â”œâ”€â”€ Bias Detection & Fairness Validation## ğŸ“‹ Compliance Support

    ai_output="positive (confidence: 0.95)",

    training_snapshot=training_snapshot,â”‚   â”œâ”€â”€ Uncertainty Quantification

    user_id="api_user"

)â”‚   â””â”€â”€ Security AssessmentCIAF provides built-in support for major regulatory frameworks:



# Step 3: Get complete audit trailâ”œâ”€â”€ Metadata Management

audit_trail = framework.get_complete_audit_trail("diagnostic_model")

â”‚   â”œâ”€â”€ Storage Backends (JSON, SQLite, Pickle)### ğŸ‡ªğŸ‡º EU AI Act

print(f"Complete audit includes:")

print(f"- {audit_trail['verification']['total_datasets']} dataset anchors")â”‚   â”œâ”€â”€ Configuration Templates- âœ… Risk Management System

print(f"- 1 model anchor with parameter fingerprints")

print(f"- {audit_trail['verification']['total_audit_records']} audit records")â”‚   â””â”€â”€ Integration Utilities- âœ… Quality Management System  

print(f"- {audit_trail['inference_chain']['total_receipts']} inference receipts")

```â””â”€â”€ Utilities- âœ… Data Governance & Bias Monitoring



### Compliance Validation    â”œâ”€â”€ CLI Tools- âœ… Technical Documentation



Automated compliance checking across multiple frameworks:    â”œâ”€â”€ Model Wrappers- âœ… Record Keeping & Audit Trails



```python    â””â”€â”€ ML Framework Simulators

from ciaf.compliance import ComplianceValidator, ComplianceFramework

```### ğŸ›ï¸ NIST AI Risk Management Framework

validator = ComplianceValidator("diagnostic_model")

- âœ… AI Risk Management Strategy

# Validate against multiple frameworks

frameworks = [## Compliance Support- âœ… AI System Inventory & Mapping

    ComplianceFramework.EU_AI_ACT,

    ComplianceFramework.NIST_AI_RMF,- âœ… Impact Assessment

    ComplianceFramework.GDPR

]**Compliance Mapping:** CIAF maps audit artifacts to controls in EU AI Act, NIST AI RMF, GDPR/HIPAA, SOX, ISO/IEC 27001. Coverage varies by control; see `docs/compliance/` for current status and gaps.- âœ… Continuous Monitoring



results = validator.validate_multiple_frameworks(

    frameworks, 

    audit_generator, ### EU AI Act### ğŸ›¡ï¸ Data Protection (GDPR, HIPAA, CCPA)

    validation_period_days=30

)- Risk Management System patterns- âœ… Data Subject Rights Management



# Get comprehensive compliance report- Quality Management System templates- âœ… Consent Tracking & Validation

summary = validator.get_validation_summary()

print(f"Compliance rate: {summary['pass_rate']:.1f}%")- Data Governance & Bias Monitoring tools- âœ… Data Minimization & Purpose Limitation

```

- Technical Documentation generation- âœ… Breach Detection & Notification

### Risk Assessment & Bias Detection

- Record Keeping & Audit Trails

Comprehensive fairness and bias validation:

### ğŸ¦ Financial & Security (SOX, PCI DSS, ISO 27001)

```python

from ciaf.compliance import BiasValidator, FairnessValidator### NIST AI Risk Management Framework- âœ… Internal Controls Over Financial Reporting



bias_validator = BiasValidator()- AI Risk Management Strategy templates- âœ… Documentation & Retention

fairness_validator = FairnessValidator()

- AI System Inventory & Mapping- âœ… Information Security Management

# Detect bias in model predictions

bias_results = bias_validator.validate_predictions(- Impact Assessment tools- âœ… Access Controls & Monitoring

    predictions=model_predictions,

    protected_attributes={"gender": gender_data, "age": age_data}- Continuous Monitoring patterns

)

## ğŸ”§ Advanced Features

# Calculate fairness metrics

fairness_metrics = fairness_validator.calculate_fairness_metrics(### Data Protection (GDPR, HIPAA, CCPA)

    predictions=model_predictions,

    protected_attributes=protected_attributes,- Data Subject Rights Management patterns### Lazy Capsule Materialization

    ground_truth=labels

)- Consent Tracking & Validation

```

- Data Minimization & Purpose LimitationCIAF's lazy evaluation system allows efficient handling of large datasets:

## CLI Tools

- Breach Detection & Notification

```bash

ciaf-setup-metadata my_project --backend sqlite --template production```python

ciaf-compliance-report eu_ai_act my_model_id --format html --output compliance_report.html

```### Financial & Security (SOX, PCI DSS, ISO 27001)# Create dataset anchor with lazy manager



## Documentation Structure- Internal Controls Over Financial Reporting# The anchor provides the cryptographic foundation for secure lazy evaluation



- **Core Concepts**: Understand CIAF's cryptographic foundations- Documentation & Retentionanchor = framework.create_dataset_anchor(

- **Compliance Guides**: Step-by-step compliance implementation

- **API Reference**: Comprehensive API documentation- Information Security Management    dataset_id="large_dataset",

- **Integration Examples**: Real-world use cases and patterns

- **Security Best Practices**: Guidelines for secure deployment- Access Controls & Monitoring    dataset_metadata={"size": "1TB", "type": "image_data"},

- See our [Security Policy](ciaf/SECURITY.md) for reporting, supported versions, and secure deployment guidance

    master_password="secure_anchor_password"

## Security Features

## Advanced Features)

See our [Security Policy](ciaf/SECURITY.md) for comprehensive security information, vulnerability reporting, and security best practices.



### Cryptographic Security

- **AES-256-GCM**: Industry-standard authenticated encryption with optional AAD support### Lazy Capsule Materialization (LCM)# Capsules are created on-demand, not stored in memory

- **SHA256**: Cryptographic hashing for integrity verification  

- **HMAC-SHA256**: Binary message authentication for anchor derivation# Each capsule is derived from the dataset anchor on materialization

- **Merkle Trees**: Canonical binary concatenation for tamper-evident data structures

CIAF's LCM system allows efficient handling of large datasets:lazy_manager = framework.lazy_managers["large_dataset"]

### Anchor Management

- **Hierarchical Anchor Derivation**: Master anchor â†’ Dataset anchor â†’ Capsule anchor hierarchy with binary HMAC anchors

- **Secure Random Generation**: Cryptographically secure randomness

- **Binary Anchor Security**: True binary anchors for maximum entropy and cryptographic strength```python# Materialize only when needed - anchor provides cryptographic verification

- **Canonical Operations**: Industry-standard anchor derivation and Merkle tree implementations

- **Legacy Compatibility**: Maintains backwards compatibility with previous key-based terminology# Create dataset anchor with lazy managercapsule = lazy_manager.materialize_capsule("item_001")



### Access Controls# The anchor provides the cryptographic foundation for secure lazy evaluation```

- **Role-Based Access**: Granular permission management

- **Audit Logging**: Comprehensive access trackinganchor = framework.create_dataset_anchor(

- **Session Management**: Secure session handling

    dataset_id="large_dataset",### âœ¨ Enhanced Model Anchor System

## Healthcare & HIPAA Compliance

    dataset_metadata={"size": "1TB", "type": "image_data"},

CIAF provides patterns for healthcare applications:

    master_password="secure_anchor_password"**NEW**: Comprehensive model tracking with immutable parameter fingerprinting:

```python

from ciaf import ModelMetadataManager)

from ciaf.compliance import ComplianceFramework

```python

# Healthcare-specific setup

manager = ModelMetadataManager("healthcare_ai", "1.0.0")# Capsules are created on-demand, not stored in memoryfrom ciaf import CIAFFramework

manager.enable_phi_protection()

manager.set_compliance_frameworks([ComplianceFramework.HIPAA])# Each capsule is derived from the dataset anchor on materialization



# Automatic PHI detection and protection patternslazy_manager = framework.lazy_managers["large_dataset"]framework = CIAFFramework("MyAI_Project")

manager.capture_metadata({

    "patient_id": "XXXXX",  # Automatically detected and protected

    "diagnosis": "diabetes",

    "consent_status": "active"# Materialize only when needed - anchor provides cryptographic verification# Create model anchor with parameter hashing (ENHANCED FEATURE)

})

```capsule = lazy_manager.materialize_capsule("item_001")model_anchor = framework.create_model_anchor(



**Note:** Patterns for PHI minimization and consent tracking are provided; final compliance depends on your deployment and data governance.```    model_name="sentiment_classifier",



## Integration Examples    model_parameters={



### Scikit-learn Integration### Enhanced Model Anchor System        "learning_rate": 2e-5,

```python

from ciaf import CIAFModelWrapper        "batch_size": 16,

from sklearn.ensemble import RandomForestClassifier

**NEW**: Comprehensive model tracking with immutable parameter fingerprinting:        "num_epochs": 3,

# Wrap your model for automatic provenance tracking

model = RandomForestClassifier()        "model_type": "bert_classifier"

wrapped_model = CIAFModelWrapper(model, "diagnostic_model_v1")

```python    },

# Training and predictions are automatically tracked

wrapped_model.fit(X_train, y_train)from ciaf import CIAFFramework    model_architecture={

predictions = wrapped_model.predict(X_test)

```        "base_model": "bert-base-uncased",



### TensorFlow/PyTorch Integrationframework = CIAFFramework("MyAI_Project")        "num_labels": 3,

```python

from ciaf.simulation import MLFrameworkSimulator        "hidden_size": 768



# Simulate ML framework interactions# Create model anchor with parameter hashing (ENHANCED FEATURE)    },

simulator = MLFrameworkSimulator("neural_network")

training_snapshot = simulator.train_model(model_anchor = framework.create_model_anchor(    authorized_datasets=["training_data_v1", "validation_data_v1"],

    training_data_capsules=capsules,

    maa=model_anchor,    model_name="diagnostic_model",    master_password="secure_model_password"

    training_params={"epochs": 50, "batch_size": 32},

    model_version="v2.0"    model_parameters={)

)

```        "learning_rate": 2e-5,



## Performance & Metrics        "batch_size": 16,print(f"Model fingerprint: {model_anchor['parameters_fingerprint']}")



CIAF provides comprehensive performance monitoring for LCM operations:        "num_epochs": 3,print(f"Architecture fingerprint: {model_anchor['architecture_fingerprint']}")



```python        "model_type": "bert_classifier"```

# Get performance metrics for lazy operations

metrics = framework.get_performance_metrics("my_dataset")    },

print(f"Materialization rate: {metrics['materialization_rate']:.2%}")

print(f"Total items: {metrics['total_items']}")    model_architecture={### ğŸ”„ Complete Audit Flow Integration

print(f"Materialized capsules: {metrics['materialized_capsules']}")

```        "base_model": "bert-base-uncased",



## Contributing        "num_labels": 3,**NEW**: End-to-end audit trail from dataset to inference:



We welcome contributions to CIAF! Please see our contributing guidelines:        "hidden_size": 768



1. **Code Style**: We use Black for code formatting    },```python

2. **Testing**: Ensure all tests pass and add tests for new features

3. **Documentation**: Update documentation for any API changes    authorized_datasets=["training_data_v1", "validation_data_v1"],# Step 1: Train with complete audit

4. **Security**: Follow secure coding practices and report security issues responsibly

    master_password="secure_model_password"training_snapshot = framework.train_model_with_audit(

### Development Setup

)    model_name="sentiment_classifier",

```bash

git clone https://github.com/DenzilGreenwood/pyciaf.git    capsules=training_capsules,

cd pyciaf

pip install -e .print(f"Model fingerprint: {model_anchor['parameters_fingerprint']}")    training_params=training_params,

```

print(f"Architecture fingerprint: {model_anchor['architecture_fingerprint']}")    model_version="1.0.0",

## License

```    user_id="data_scientist_alice"

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

)

## Support & Community

### Complete Audit Flow Integration

- **Documentation**: [https://ciaf.readthedocs.io](https://ciaf.readthedocs.io)

- **Issues**: [GitHub Issues](https://github.com/DenzilGreenwood/pyciaf/issues)# Step 2: Perform inference with audit chain

- **Discussions**: [GitHub Discussions](https://github.com/DenzilGreenwood/pyciaf/discussions)

- **Security**: [Security Policy](ciaf/SECURITY.md)**NEW**: End-to-end audit trail from dataset to inference:receipt = framework.perform_inference_with_audit(



## Acknowledgments    model_name="sentiment_classifier",



CIAF is built on the shoulders of giants. We acknowledge the following projects and standards:```python    query="This product is amazing!",



- **Cryptography**: Built on the excellent `cryptography` library# Step 1: Train with complete audit    ai_output="positive (confidence: 0.95)",

- **Regulatory Frameworks**: Implements guidelines from EU AI Act, NIST AI RMF, and others

training_snapshot = framework.train_model_with_audit(    training_snapshot=training_snapshot,

---

    model_name="diagnostic_model",    user_id="api_user"

**Personal Note**: This project is a work in progress and reflects my passion for secure and compliant AI systems. Feedback and contributions are highly appreciated!

    capsules=training_capsules,)

*- Denzil James Greenwood*
    training_params=training_params,

    model_version="1.0.0",# Step 3: Get complete audit trail

    user_id="data_scientist_alice"audit_trail = framework.get_complete_audit_trail("sentiment_classifier")

)

print(f"Complete audit includes:")

# Step 2: Perform inference with audit chainprint(f"- {audit_trail['verification']['total_datasets']} dataset anchors")

receipt = framework.perform_inference_with_audit(print(f"- 1 model anchor with parameter fingerprints")

    model_name="diagnostic_model",print(f"- {audit_trail['verification']['total_audit_records']} audit records")

    query="This product is amazing!",print(f"- {audit_trail['inference_chain']['total_receipts']} inference receipts")

    ai_output="positive (confidence: 0.95)",```

    training_snapshot=training_snapshot,

    user_id="api_user"### Compliance Validation

)

Automated compliance checking across multiple frameworks:

# Step 3: Get complete audit trail

audit_trail = framework.get_complete_audit_trail("diagnostic_model")```python

from ciaf.compliance import ComplianceValidator, ComplianceFramework

print(f"Complete audit includes:")

print(f"- {audit_trail['verification']['total_datasets']} dataset anchors")validator = ComplianceValidator("my_model")

print(f"- 1 model anchor with parameter fingerprints")

print(f"- {audit_trail['verification']['total_audit_records']} audit records")# Validate against multiple frameworks

print(f"- {audit_trail['inference_chain']['total_receipts']} inference receipts")frameworks = [

```    ComplianceFramework.EU_AI_ACT,

    ComplianceFramework.NIST_AI_RMF,

### Compliance Validation    ComplianceFramework.GDPR

]

Automated compliance checking across multiple frameworks:

results = validator.validate_multiple_frameworks(

```python    frameworks, 

from ciaf.compliance import ComplianceValidator, ComplianceFramework    audit_generator, 

    validation_period_days=30

validator = ComplianceValidator("diagnostic_model"))



# Validate against multiple frameworks# Get comprehensive compliance report

frameworks = [summary = validator.get_validation_summary()

    ComplianceFramework.EU_AI_ACT,print(f"Compliance rate: {summary['pass_rate']:.1f}%")

    ComplianceFramework.NIST_AI_RMF,```

    ComplianceFramework.GDPR

]### Risk Assessment & Bias Detection



results = validator.validate_multiple_frameworks(Comprehensive fairness and bias validation:

    frameworks, 

    audit_generator, ```python

    validation_period_days=30from ciaf.compliance import BiasValidator, FairnessValidator

)

bias_validator = BiasValidator()

# Get comprehensive compliance reportfairness_validator = FairnessValidator()

summary = validator.get_validation_summary()

print(f"Compliance rate: {summary['pass_rate']:.1f}%")# Detect bias in model predictions

```bias_results = bias_validator.validate_predictions(

    predictions=model_predictions,

### Risk Assessment & Bias Detection    protected_attributes={"gender": gender_data, "age": age_data}

)

Comprehensive fairness and bias validation:

# Calculate fairness metrics

```pythonfairness_metrics = fairness_validator.calculate_fairness_metrics(

from ciaf.compliance import BiasValidator, FairnessValidator    predictions=model_predictions,

    protected_attributes=protected_attributes,

bias_validator = BiasValidator()    ground_truth=labels

fairness_validator = FairnessValidator())

```

# Detect bias in model predictions

bias_results = bias_validator.validate_predictions(## ğŸ› ï¸ CLI Tools

    predictions=model_predictions,

    protected_attributes={"gender": gender_data, "age": age_data}CIAF includes command-line tools for common operations:

)

### Setup Metadata Storage

# Calculate fairness metrics```bash

fairness_metrics = fairness_validator.calculate_fairness_metrics(ciaf-setup-metadata my_project --backend sqlite --template production

    predictions=model_predictions,```

    protected_attributes=protected_attributes,

    ground_truth=labels### Generate Compliance Reports

)```bash

```ciaf-compliance-report eu_ai_act my_model_id --format html --output compliance_report.html

```

## CLI Tools

## ğŸ“š Documentation Structure

```bash

ciaf-setup-metadata my_project --backend sqlite --template production- **Core Concepts**: Understand CIAF's cryptographic foundations

ciaf-compliance-report eu_ai_act my_model_id --format html --output compliance_report.html- **Compliance Guides**: Step-by-step compliance implementation

```- **API Reference**: Comprehensive API documentation

- **Integration Examples**: Real-world use cases and patterns

## Documentation Structure- **Security Best Practices**: Guidelines for secure deployment

- **[ciaf/SECURITY.md](ciaf/SECURITY.md)**: Comprehensive security policy and vulnerability reporting

- **Core Concepts**: Understand CIAF's cryptographic foundations

- **Compliance Guides**: Step-by-step compliance implementation## ğŸ”’ Security Features

- **API Reference**: Comprehensive API documentation

- **Integration Examples**: Real-world use cases and patterns> **ğŸ›¡ï¸ For comprehensive security information, vulnerability reporting, and security best practices, see our [ciaf/SECURITY.md](ciaf/SECURITY.md) file.**

- **Security Best Practices**: Guidelines for secure deployment

- See our [Security Policy](ciaf/SECURITY.md) for reporting, supported versions, and secure deployment guidance### Cryptographic Security

- **AES-256-GCM**: Industry-standard authenticated encryption with optional AAD support

## Security Features- **SHA256**: Cryptographic hashing for integrity verification  

- **HMAC-SHA256**: Binary message authentication for anchor derivation

See our [Security Policy](ciaf/SECURITY.md) for comprehensive security information, vulnerability reporting, and security best practices.- **Merkle Trees**: Canonical binary concatenation for tamper-evident data structures



### Cryptographic Security### Anchor Management

- **AES-256-GCM**: Industry-standard authenticated encryption with optional AAD support- **Hierarchical Anchor Derivation**: Master anchor â†’ Dataset anchor â†’ Capsule anchor hierarchy with binary HMAC anchors

- **SHA256**: Cryptographic hashing for integrity verification  - **Secure Random Generation**: Cryptographically secure randomness

- **HMAC-SHA256**: Binary message authentication for anchor derivation- **Binary Anchor Security**: True binary anchors for maximum entropy and cryptographic strength

- **Merkle Trees**: Canonical binary concatenation for tamper-evident data structures- **Canonical Operations**: Industry-standard anchor derivation and Merkle tree implementations

- **Legacy Compatibility**: Maintains backwards compatibility with previous key-based terminology

### Anchor Management

- **Hierarchical Anchor Derivation**: Master anchor â†’ Dataset anchor â†’ Capsule anchor hierarchy with binary HMAC anchors### Access Controls

- **Secure Random Generation**: Cryptographically secure randomness- **Role-Based Access**: Granular permission management

- **Binary Anchor Security**: True binary anchors for maximum entropy and cryptographic strength- **Audit Logging**: Comprehensive access tracking

- **Canonical Operations**: Industry-standard anchor derivation and Merkle tree implementations- **Session Management**: Secure session handling

- **Legacy Compatibility**: Maintains backwards compatibility with previous key-based terminology

## ğŸ¥ Healthcare & HIPAA Compliance

### Access Controls

- **Role-Based Access**: Granular permission managementCIAF provides specialized support for healthcare applications:

- **Audit Logging**: Comprehensive access tracking

- **Session Management**: Secure session handling```python

from ciaf import ModelMetadataManager

## Healthcare & HIPAA Compliancefrom ciaf.compliance import ComplianceFramework



CIAF provides patterns for healthcare applications:# Healthcare-specific setup

manager = ModelMetadataManager("healthcare_ai", "1.0.0")

```pythonmanager.enable_phi_protection()

from ciaf import ModelMetadataManagermanager.set_compliance_frameworks([ComplianceFramework.HIPAA])

from ciaf.compliance import ComplianceFramework

# Automatic PHI detection and protection

# Healthcare-specific setupmanager.capture_metadata({

manager = ModelMetadataManager("healthcare_ai", "1.0.0")    "patient_id": "XXXXX",  # Automatically detected and protected

manager.enable_phi_protection()    "diagnosis": "diabetes",

manager.set_compliance_frameworks([ComplianceFramework.HIPAA])    "consent_status": "active"

})

# Automatic PHI detection and protection patterns```

manager.capture_metadata({

    "patient_id": "XXXXX",  # Automatically detected and protected## ğŸŒ Integration Examples

    "diagnosis": "diabetes",

    "consent_status": "active"### Scikit-learn Integration

})```python

```from ciaf import CIAFModelWrapper

from sklearn.ensemble import RandomForestClassifier

**Note:** Patterns for PHI minimization and consent tracking are provided; final compliance depends on your deployment and data governance.

# Wrap your model for automatic provenance tracking

## Integration Examplesmodel = RandomForestClassifier()

wrapped_model = CIAFModelWrapper(model, "fraud_detection_v1")

### Scikit-learn Integration

```python# Training and predictions are automatically tracked

from ciaf import CIAFModelWrapperwrapped_model.fit(X_train, y_train)

from sklearn.ensemble import RandomForestClassifierpredictions = wrapped_model.predict(X_test)

```

# Wrap your model for automatic provenance tracking

model = RandomForestClassifier()### TensorFlow/PyTorch Integration

wrapped_model = CIAFModelWrapper(model, "diagnostic_model_v1")```python

from ciaf.simulation import MLFrameworkSimulator

# Training and predictions are automatically tracked

wrapped_model.fit(X_train, y_train)# Simulate ML framework interactions

predictions = wrapped_model.predict(X_test)simulator = MLFrameworkSimulator("neural_network")

```training_snapshot = simulator.train_model(

    training_data_capsules=capsules,

### TensorFlow/PyTorch Integration    maa=model_anchor,

```python    training_params={"epochs": 50, "batch_size": 32},

from ciaf.simulation import MLFrameworkSimulator    model_version="v2.0"

)

# Simulate ML framework interactions```

simulator = MLFrameworkSimulator("neural_network")

training_snapshot = simulator.train_model(## ğŸ“Š Performance & Metrics

    training_data_capsules=capsules,

    maa=model_anchor,CIAF provides comprehensive performance monitoring:

    training_params={"epochs": 50, "batch_size": 32},

    model_version="v2.0"```python

)# Get performance metrics for lazy operations

```metrics = framework.get_performance_metrics("my_dataset")

print(f"Materialization rate: {metrics['materialization_rate']:.2%}")

## Performance & Metricsprint(f"Total items: {metrics['total_items']}")

print(f"Materialized capsules: {metrics['materialized_capsules']}")

CIAF provides comprehensive performance monitoring for LCM operations:```



```python## ğŸ¤ Contributing

# Get performance metrics for lazy operations

metrics = framework.get_performance_metrics("my_dataset")We welcome contributions to CIAF! Please see our contributing guidelines:

print(f"Materialization rate: {metrics['materialization_rate']:.2%}")

print(f"Total items: {metrics['total_items']}")1. **Code Style**: We use Black for code formatting

print(f"Materialized capsules: {metrics['materialized_capsules']}")2. **Testing**: Ensure all tests pass and add tests for new features

```3. **Documentation**: Update documentation for any API changes

4. **Security**: Follow secure coding practices and report security issues responsibly

## Contributing

### Development Setup

We welcome contributions to CIAF! Please see our contributing guidelines:

```bash

1. **Code Style**: We use Black for code formattinggit clone https://github.com/DenzilGreenwood/pyciaf.git

2. **Testing**: Ensure all tests pass and add tests for new featurescd pyciaf

3. **Documentation**: Update documentation for any API changespip install -e .

4. **Security**: Follow secure coding practices and report security issues responsibly```



### Development Setup## ğŸ†˜ Support & Community



```bash- **Documentation**: [https://ciaf.readthedocs.io](https://ciaf.readthedocs.io)

git clone https://github.com/DenzilGreenwood/pyciaf.git- **Issues**: [GitHub Issues](https://github.com/DenzilGreenwood/pyciaf/issues)

cd pyciaf- **Discussions**: [GitHub Discussions](https://github.com/DenzilGreenwood/pyciaf/discussions)

pip install -e .- **Security**: [Security Policy](ciaf/SECURITY.md)

```

## ï¿½ï¸ Status & Roadmap

### Current Status

| Feature | Status | Notes |
|---------|--------|-------|
| **Core Framework** | âœ… Working | Basic anchoring and LCM |
| **Cryptographic Primitives** | âœ… Working | SHA-256, HMAC, AES-GCM |
| **Merkle Trees** | âœ… Working | Deterministic proof generation |
| **Dataset Anchoring** | âœ… Working | Hierarchical anchor derivation |
| **Model Anchoring** | âœ… Working | Parameter/architecture fingerprinting |
| **Audit Trails** | âœ… Working | Hash-chained event logging |
| **Lazy Materialization** | âœ… Working | On-demand capsule generation |
| **Basic CLI** | ğŸ§ª Prototype | Setup and compliance commands |
| **Compliance Mapping** | ğŸ§ª Prototype | EU AI Act, NIST frameworks |
| **Receipt Verification** | âœ… Working | Independent verifier tool |
| **Healthcare Patterns** | ğŸ§ª Prototype | PHI protection scaffolding |

### Near-term Roadmap (Q4 2024)

| Feature | Priority | Target |
|---------|----------|--------|
| **API Stabilization** | ğŸ”´ High | Finalize public APIs |
| **Documentation** | ğŸ”´ High | Complete API reference |
| **Test Coverage** | ğŸ”´ High | >90% test coverage |
| **Performance Optimization** | ğŸŸ¡ Medium | LCM efficiency improvements |
| **CLI Enhancement** | ğŸŸ¡ Medium | Full-featured command interface |

### Medium-term Roadmap (2025)

| Feature | Priority | Target |
|---------|----------|--------|
| **GDPR/HIPAA Compliance** | ğŸ”´ High | Production-ready patterns |
| **Advanced Analytics** | ğŸŸ¡ Medium | Bias detection, fairness metrics |
| **Integration Libraries** | ğŸŸ¡ Medium | TensorFlow, PyTorch wrappers |
| **Web Dashboard** | ğŸŸ¢ Low | Browser-based audit visualization |
| **Enterprise Features** | ğŸ“‹ Planned | SSO, RBAC, enterprise deployment |

### Research Areas

- **Zero-Knowledge Proofs**: Explore ZK-SNARKs for privacy-preserving verification
- **Distributed Ledger**: Investigate blockchain integration for audit immutability
- **Homomorphic Encryption**: Enable computation on encrypted training data
- **Formal Verification**: Mathematical proofs of cryptographic correctness

## ï¿½ğŸ™ Acknowledgments

## License

CIAF is built on the shoulders of giants. We acknowledge the following projects and standards:

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

- **Cryptography**: Built on the excellent `cryptography` library

## Support & Community- **Regulatory Frameworks**: Implements guidelines from EU AI Act, NIST AI RMF, and others



- **Documentation**: [https://ciaf.readthedocs.io](https://ciaf.readthedocs.io)---

- **Issues**: [GitHub Issues](https://github.com/DenzilGreenwood/pyciaf/issues)

- **Discussions**: [GitHub Discussions](https://github.com/DenzilGreenwood/pyciaf/discussions)**Personal Note**: This project is a work in progress and reflects my passion for secure and compliant AI systems. Feedback and contributions are highly appreciated!

- **Security**: [Security Policy](ciaf/SECURITY.md)

*- Denzil James Greenwood*

## Acknowledgments



CIAF is built on the shoulders of giants. We acknowledge the following projects and standards:

- **Cryptography**: Built on the excellent `cryptography` library
- **Regulatory Frameworks**: Implements guidelines from EU AI Act, NIST AI RMF, and others

---

**Personal Note**: This project is a work in progress and reflects my passion for secure and compliant AI systems. Feedback and contributions are highly appreciated!

*- Denzil James Greenwood*
